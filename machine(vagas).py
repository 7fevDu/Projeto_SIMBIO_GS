# -*- coding: utf-8 -*-
"""machine_vagas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FsPfE4hz-Y6VCBxjyhAonTbjKp5cwmkN
"""

# pip install sentence-transformers

import pandas as pd
import numpy as np
import matplotlib
import pandas as pd
import ast
import re

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

from sklearn.metrics import silhouette_score

url = "https://docs.google.com/spreadsheets/d/1jAqJJb3870zLfGE1_Xz1cJbnfDkct3lx/export?format=xlsx"

df_vagas = pd.read_excel(url, engine="openpyxl")
df_vagas

url1 = "https://docs.google.com/spreadsheets/d/1H8CicVQoYdVmzSGsLgm8LslU4CS5UZLK/export?format=xlsx"

df_pessoas = pd.read_excel(url1)

df_pessoas.head(5)

"""Funcao de limpeza"""

def clean_text(txt):
    if pd.isna(txt):
        return""
    txt = str(txt)
    txt = re.sub(r"\s+", "", txt).strip()
    return txt

df_vagas.head()

""" LIMPAR COLUNAS IMPORTANTES"""

df_vagas["area"] = df_vagas["area"].apply(clean_text)
df_vagas["vaga"] = df_vagas["vaga"].apply(clean_text)
df_vagas["qualidades"] = df_vagas["qualidades"].apply(clean_text)

"""CRIAR COLUNA PERFIL_VAGA"""

df_vagas["perfil_vaga"] = (
    df_vagas["area"] + " | " +
    df_vagas["vaga"] + " | " +
    df_vagas["qualidades"]
)

"""GERAR EMBEDDINGS DAS VAGAS"""

from sentence_transformers import SentenceTransformer



model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

emb_vagas = model.encode(
    df_vagas["perfil_vaga"].tolist(),
    show_progress_bar=True
)

# transformar em dataframe, se quiser salvar
df_emb_vagas = pd.DataFrame(emb_vagas)

df_vagas.head()

"""Apenas salvando"""

df_vagas.to_excel("vagas_trabalhadas.xlsx", index=False)
df_emb_vagas.to_excel("embeddings_vagas.xlsx", index=False)

df_vagas.head()

df_pessoas["area"] = df_pessoas["area"].apply(clean_text)
df_pessoas["emprego"] = df_pessoas["emprego"].apply(clean_text)
df_pessoas["qualidades"] = df_pessoas["qualidades"].apply(clean_text)
df_pessoas["texto"] = df_pessoas["texto"].apply(clean_text)

# LIMPAR VAGAS
df_vagas["area"] = df_vagas["area"].apply(clean_text)
df_vagas["vaga"] = df_vagas["vaga"].apply(clean_text)
df_vagas["qualidades"] = df_vagas["qualidades"].apply(clean_text)
df_vagas["perfil_vaga"] = df_vagas["perfil_vaga"].apply(clean_text)

"""CRIAR PERFIL COMPLETO DAS PESSOAS (se não existir)"""

if "perfil_completo" not in df_pessoas.columns:
    df_pessoas["perfil_completo"] = (
        df_pessoas["area"] + " | " +
        df_pessoas["emprego"] + " | " +
        df_pessoas["qualidades"] + " | " +
        df_pessoas["texto"]
    )

""" CARREGAR MODELO DE EMBEDDINGS"""

model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

"""GERAR EMBEDDINGS"""

print("Gerando embeddings das pessoas...")
emb_pessoas = model.encode(df_pessoas["perfil_completo"].tolist(), show_progress_bar=True)

print("Gerando embeddings das vagas...")
emb_vagas = model.encode(df_vagas["perfil_vaga"].tolist(), show_progress_bar=True)

"""CALCULAR SIMILARIDADE"""

similaridade = cosine_similarity(emb_pessoas, emb_vagas)
# linhas = pessoas | colunas = vagas

"""FUNÇÃO PARA PEGAR TOP N VAGAS POR PESSOA"""

def recomendar_vagas(idx_pessoa, top_n=5):
    scores = similaridade[idx_pessoa]
    top_idx = scores.argsort()[::-1][:top_n]

    resultados = []
    for i in top_idx:
        resultados.append({
            "vaga": df_vagas.iloc[i]["vaga"],
            "area_vaga": df_vagas.iloc[i]["area"],
            "qualidades_vaga": df_vagas.iloc[i]["qualidades"],
            "score": float(round(scores[i], 4))
        })
    return resultados

"""GERAR TABELA FINAL DE RECOMENDAÇÕE"""

lista_final = []

for i in range(len(df_pessoas)):
    pessoa = df_pessoas.iloc[i]
    recomendadas = recomendar_vagas(i, top_n=5)

    for rec in recomendadas:
        lista_final.append({
            "nome": pessoa["nome"],
            "area_atual": pessoa["area"],
            "emprego_atual": pessoa["emprego"],
            "qualidades_pessoa": pessoa["qualidades"],
            "vaga_sugerida": rec["vaga"],
            "area_vaga": rec["area_vaga"],
            "qualidades_vaga": rec["qualidades_vaga"],
            "similaridade": rec["score"]
        })

df_matches = pd.DataFrame(lista_final)

"""SALVAR RESULTADOS"""

df_matches.to_excel("recomendacoes_pessoas_vagas.xlsx", index=False)

df_matches.head(50)

melhor_match = []

for i in range(len(df_pessoas)):
    scores = similaridade[i]  # linha da matriz = pessoa i
    best_idx = scores.argmax()  # índice da vaga com maior similaridade
    best_score = scores[best_idx]

    melhor_match.append({
        "nome": df_pessoas.iloc[i]["nome"],
        "area_atual": df_pessoas.iloc[i]["area"],
        "emprego_atual": df_pessoas.iloc[i]["emprego"],
        "qualidades_pessoa": df_pessoas.iloc[i]["qualidades"],

        "vaga_recomendada": df_vagas.iloc[best_idx]["vaga"],
        "area_vaga": df_vagas.iloc[best_idx]["area"],
        "qualidades_vaga": df_vagas.iloc[best_idx]["qualidades"],

        "similaridade": round(float(best_score), 4)
    })

df_direcionamento = pd.DataFrame(melhor_match)

df_direcionamento.head(50)

df_direcionamento.to_excel("pessoa_para_vaga_unica.xlsx", index=False)

print("Gerando embeddings das pessoas...")

model = SentenceTransformer("all-MiniLM-L6-v2")

pessoas_embeddings = model.encode(
    df_pessoas["perfil_completo"].tolist(),
    show_progress_bar=True
)

df_pessoas["embedding"] = list(pessoas_embeddings)

print("Embeddings de pessoas criados com sucesso!")


# ===============================================
# 3) GERAR EMBEDDINGS DAS VAGAS
# ===============================================

print("Gerando embeddings das vagas...")

vagas_embeddings = model.encode(
    df_vagas["perfil_vaga"].tolist(),
    show_progress_bar=True
)

df_vagas["embedding"] = list(vagas_embeddings)

print("Embeddings de vagas criados com sucesso!")


# ===============================================
# 4) FUNÇÃO — RECOMENDAR VAGAS PARA UMA PESSOA
# ===============================================

def recomendar_vagas_para_pessoa(id_pessoa, top_n=5):

    emb_p = np.array(df_pessoas.loc[id_pessoa, "embedding"]).reshape(1, -1)
    vagas_emb = np.vstack(df_vagas["embedding"].values)

    sims = cosine_similarity(emb_p, vagas_emb)[0]
    top_idx = sims.argsort()[::-1][:top_n]

    resultado = df_vagas.iloc[top_idx].copy()
    resultado["similaridade"] = sims[top_idx]

    return resultado[["vaga", "area", "qualidades", "similaridade"]]


# ===============================================
# 5) FUNÇÃO — RECOMENDAR PESSOAS PARA UMA VAGA
# ===============================================

def recomendar_pessoas_para_vaga(id_vaga, top_n=5):

    emb_v = np.array(df_vagas.loc[id_vaga, "embedding"]).reshape(1, -1)
    pessoas_emb = np.vstack(df_pessoas["embedding"].values)

    sims = cosine_similarity(emb_v, pessoas_emb)[0]
    top_idx = sims.argsort()[::-1][:top_n]

    resultado = df_pessoas.iloc[top_idx].copy()
    resultado["similaridade"] = sims[top_idx]

    return resultado[["nome", "area", "emprego", "similaridade"]]

def similaridade_entre_pessoas(id1, id2):
    v1 = np.array(df_pessoas.loc[id1, "embedding"]).reshape(1, -1)
    v2 = np.array(df_pessoas.loc[id2, "embedding"]).reshape(1, -1)
    return float(cosine_similarity(v1, v2)[0])

def validar_matching_pessoa(id_pessoa):
    resultados = recomendar_vagas_para_pessoa(id_pessoa, top_n=10)

    area_pessoa = df_pessoas.loc[id_pessoa, "area"]
    resultados["match_area"] = resultados["area"].apply(lambda a: a == area_pessoa)

    return resultados

X = np.vstack(df_pessoas["embedding"].values)
labels = df_pessoas["cluster"]

silhouette = silhouette_score(X, labels)
silhouette

def avaliar_matching_automatico(n=100):
    acertos = []

    for i in range(n):
        pessoa_area = df_pessoas.loc[i, "area"]
        recomendadas = recomendar_vagas_para_pessoa(i, top_n=5)


        score = sum(recomendadas["area"] == pessoa_area)
        acertos.append(score)

    return np.mean(acertos)

def avaliar_matching_automatico(n=100, top_n=5):
    resultados = []

    total = min(n, len(df_pessoas))

    for i in range(total):
        area_pessoa = df_pessoas.loc[i, "area"]

        recomendadas = recomendar_vagas_para_pessoa(i, top_n=top_n)

        # conta quantas vagas têm a mesma área
        acertos = sum(recomendadas["area"] == area_pessoa)

        resultados.append(acertos)

    return resultados



resultados = avaliar_matching_automatico(n=100, top_n=5)

media = np.mean(resultados)

print("===========================================")
print(f"SCORE MÉDIO DE ACERTO POR PESSOA (0–5): {media:.2f}")
print("===========================================")
print("\nInterpretação:")
print("0.0 → péssimo")
print("1.0 → aceitável")
print("2.0 → muito bom")
print("3.0+ → excelente")
print("5.0 → perfeito")
print("===========================================\n")

import pickle

with open("dados_pessoas.pkl", "wb") as f:
    pickle.dump(df_pessoas, f)

with open("dados_vagas.pkl", "wb") as f:
    pickle.dump(df_vagas, f)

print("Arquivos .pkl criados com sucesso!")
